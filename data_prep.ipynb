{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the original dataset, we are given about 3500 images. In each image, there are multiple characters, a rough average of 180 per image. The original train.csv file has one row for each image. The labels are separated by spaces and include the unicode character, x position start, y position start, width, and height of the area where the character is. \n",
    "\n",
    "First, we're going to turn this into a new dataframe where each character from each image has it's own row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>height</th>\n",
       "      <th>image_id</th>\n",
       "      <th>width</th>\n",
       "      <th>x_start</th>\n",
       "      <th>y_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U+306F</td>\n",
       "      <td>53</td>\n",
       "      <td>100241706_00004_2</td>\n",
       "      <td>133</td>\n",
       "      <td>1231</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U+304C</td>\n",
       "      <td>69</td>\n",
       "      <td>100241706_00004_2</td>\n",
       "      <td>84</td>\n",
       "      <td>275</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U+3044</td>\n",
       "      <td>69</td>\n",
       "      <td>100241706_00004_2</td>\n",
       "      <td>143</td>\n",
       "      <td>1495</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U+3051</td>\n",
       "      <td>91</td>\n",
       "      <td>100241706_00004_2</td>\n",
       "      <td>53</td>\n",
       "      <td>220</td>\n",
       "      <td>3331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U+306B</td>\n",
       "      <td>92</td>\n",
       "      <td>100241706_00004_2</td>\n",
       "      <td>61</td>\n",
       "      <td>911</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character height           image_id width x_start y_start\n",
       "0    U+306F     53  100241706_00004_2   133    1231    3465\n",
       "1    U+304C     69  100241706_00004_2    84     275    1652\n",
       "2    U+3044     69  100241706_00004_2   143    1495    1218\n",
       "3    U+3051     91  100241706_00004_2    53     220    3331\n",
       "4    U+306B     92  100241706_00004_2    61     911    1452"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "new_rows = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    label_array = row[\"labels\"].split()\n",
    "    length = int(len(label_array) / 5)\n",
    "    for i in range(0,length):\n",
    "        new_row = {}\n",
    "        new_row[\"image_id\"] = row[\"image_id\"]\n",
    "        new_row[\"x_start\"] = label_array[(i*5)+1]\n",
    "        new_row[\"y_start\"] = label_array[(i*5)+2]\n",
    "        new_row[\"width\"] = label_array[(i*5)+3]\n",
    "        new_row[\"height\"] = label_array[(i*5)+4]\n",
    "        new_row[\"character\"] = label_array[(i*5)+0]\n",
    "        new_rows.append(new_row)    \n",
    "\n",
    "\n",
    "labels_to_features = pd.DataFrame(new_rows)\n",
    "labels_to_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>height</th>\n",
       "      <th>image_id</th>\n",
       "      <th>width</th>\n",
       "      <th>x_start</th>\n",
       "      <th>y_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>683464</td>\n",
       "      <td>683464</td>\n",
       "      <td>683464</td>\n",
       "      <td>683464</td>\n",
       "      <td>683464</td>\n",
       "      <td>683464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4212</td>\n",
       "      <td>455</td>\n",
       "      <td>3605</td>\n",
       "      <td>333</td>\n",
       "      <td>2826</td>\n",
       "      <td>3927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>U+306B</td>\n",
       "      <td>84</td>\n",
       "      <td>200014685-00010_1</td>\n",
       "      <td>84</td>\n",
       "      <td>683</td>\n",
       "      <td>1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>24685</td>\n",
       "      <td>10061</td>\n",
       "      <td>614</td>\n",
       "      <td>9813</td>\n",
       "      <td>554</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character  height           image_id   width x_start y_start\n",
       "count     683464  683464             683464  683464  683464  683464\n",
       "unique      4212     455               3605     333    2826    3927\n",
       "top       U+306B      84  200014685-00010_1      84     683    1328\n",
       "freq       24685   10061                614    9813     554     349"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest counts: \n",
      "            count\n",
      "character       \n",
      "U+003F         1\n",
      "U+717D         1\n",
      "U+717B         1\n",
      "U+716C         1\n",
      "U+7165         1\n",
      "highest counts: \n",
      "            count\n",
      "character       \n",
      "U+3092     15743\n",
      "U+3068     16588\n",
      "U+3066     20569\n",
      "U+3057     22209\n",
      "U+306E     24136\n"
     ]
    }
   ],
   "source": [
    "char_counts = pd.DataFrame(labels_to_features.groupby(['character']).size(), columns=[\"count\"])\n",
    "print(\"lowest counts: \\n\", char_counts.sort_values(by=[\"count\"])[0:5])\n",
    "print(\"highest counts: \\n\", char_counts.sort_values(by=[\"count\"])[-6:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# char_counts_1 = set(char_counts.index[char_counts['count'] <= 1].tolist())\n",
    "# print(\"Dropping\", len(char_counts_1), \"rows where there was only one instance of the character.\")\n",
    "# labels_to_features_over_1 = labels_to_features[~labels_to_features['character'].isin(char_counts_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile as zf\n",
    "\n",
    "# files = zf.ZipFile(\"train_images.zip\", 'r')\n",
    "# files.extractall('train')\n",
    "# files.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's cut down the \"unique\" character count of a whopping 4212. We can do this by separating the data into three data sets based on the character type and handle them separately for now.\n",
    "\n",
    "This would be a good step for a layer in a deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "df_hiragana = pd.read_csv(\"hiragana.csv\")\n",
    "df_katakana = pd.read_csv(\"katakana.csv\")\n",
    "set_hiragana = set(df_hiragana[\"unicode\"])\n",
    "set_katakana = set(df_katakana[\"unicode\"])\n",
    "print(len(set_hiragana))\n",
    "print(len(set_katakana))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def writeToCSV(file, img_size, labels_to_features,alphabet = \"all\", limit = float(\"inf\")):\n",
    "    # Write column headers to the file\n",
    "    for i in range(img_size * img_size):\n",
    "        file.write(str(i) + \",\")\n",
    "    file.write(\"character\")\n",
    "    file.write(\"\\n\")\n",
    "    \n",
    "    curr_file_name = \"\"\n",
    "    curr_img = []\n",
    "    for row in labels_to_features.iterrows():\n",
    "        # set a limit for testing purposes\n",
    "        if row[0] > limit:\n",
    "            break\n",
    "            \n",
    "        row = row[1]\n",
    "        # skip anything not in the alphabet we specified\n",
    "        label = row[\"character\"]\n",
    "        if alphabet == \"hiragana\" and label not in set_hiragana:\n",
    "            continue\n",
    "        if alphabet == \"katakana\" and label not in set_katakana:\n",
    "            continue\n",
    "        if alphabet == \"kanji\" and (label in set_hiragana or label in set_katakana):\n",
    "            continue\n",
    "        \n",
    "        # for each image, we want to convert it to black n white, with a threshhold for easy reading\n",
    "        # they're in order based on file name, so we can do this just once per image and save it until\n",
    "        #    another image appears in the loop\n",
    "        filename = \"train/\" + row[\"image_id\"] + \".jpg\"\n",
    "        if filename != curr_file_name: \n",
    "            orig_img = cv.imread(filename)\n",
    "            bw_img = cv.cvtColor(orig_img, cv.COLOR_RGB2GRAY )\n",
    "            thresh_img = cv.adaptiveThreshold(bw_img,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,101,17)\n",
    "            curr_file_name = filename\n",
    "            curr_img = thresh_img        \n",
    "\n",
    "        width = int(row[\"width\"])\n",
    "        height = int(row[\"height\"])\n",
    "        start_row = int(row[\"x_start\"])\n",
    "        start_col = int(row[\"y_start\"])\n",
    "        end_row = start_row + width\n",
    "        end_col = start_col + height\n",
    "        \n",
    "        char_img = curr_img[start_col:end_col,start_row:end_row]\n",
    "        \n",
    "        # resize image to the specified size and pad it to make it a square\n",
    "        padding = []\n",
    "        if height > width:\n",
    "            new_height = img_size\n",
    "            new_width = int((width*new_height)/(height))\n",
    "            if new_width % 2 == 1:\n",
    "                new_width += 1\n",
    "            pad = int((img_size-new_width)/2)\n",
    "            padding = [0,0,pad,pad]\n",
    "        else:\n",
    "            new_width = img_size\n",
    "            new_height = int((height*new_width)/(width))\n",
    "            if new_height % 2 == 1:\n",
    "                new_height += 1\n",
    "            pad = int((img_size-new_height)/2)\n",
    "            padding = [pad,pad,0,0]\n",
    "        sm_char_img = cv.resize(char_img, (new_width,new_height), interpolation = cv.INTER_AREA)     \n",
    "        norm_char_img = cv.copyMakeBorder(sm_char_img, padding[0], padding[1], padding[2], padding[3], cv.BORDER_CONSTANT,value=[255,255,255])\n",
    "\n",
    "#         plt.figure(figsize=(1,1))\n",
    "#         plt.imshow(norm_char_img, cmap=plt.cm.gray, interpolation='nearest')\n",
    "        \n",
    "        for row in norm_char_img:\n",
    "            for i in range(0,len(row)):\n",
    "                f.write(str(row[i])+\",\")\n",
    "        file.write(label)\n",
    "        file.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAMPLE\n",
    "# f = open(\"all_hiragana2.csv\", \"w\")\n",
    "# writeToCSV(f,30,labels_to_features,\"hiragana\",100)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = datetime.datetime.now()\n",
    "\n",
    "# f = open(\"all_hiragana.csv\", \"w\")\n",
    "# writeToCSV(f,30,labels_to_features,\"hiragana\")\n",
    "# f.close()\n",
    "\n",
    "# print(\"Time to complete:\", datetime.datetime.now() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = datetime.datetime.now()\n",
    "\n",
    "# f = open(\"all_katakana.csv\", \"w\")\n",
    "# writeToCSV(f,30,labels_to_features,\"katakana\")\n",
    "# f.close()\n",
    "\n",
    "# print(\"Time to complete:\", datetime.datetime.now() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to complete: 0:16:02.647281\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "f = open(\"all_kanji.csv\", \"w\")\n",
    "writeToCSV(f,30,labels_to_features,\"kanji\")\n",
    "f.close()\n",
    "\n",
    "print(\"Time to complete:\", datetime.datetime.now() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to complete: 0:30:07.293539\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "f = open(\"all_chars.csv\", \"w\")\n",
    "writeToCSV(f,30,labels_to_features)\n",
    "f.close()\n",
    "\n",
    "print(\"Time to complete:\", datetime.datetime.now() - now)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
